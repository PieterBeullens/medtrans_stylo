{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preproc import preprocess_and_slice_text_files\n",
    "import logging\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:'BurCom.txt' was processed and split into 24 samples\n",
      "INFO:root:'AristPha.txt' was processed and split into 20 samples\n",
      "INFO:root:'BurInt.txt' was processed and split into 64 samples\n",
      "INFO:root:'AnonMetaph.txt' was processed and split into 61 samples\n",
      "INFO:root:'BurEthN.txt' was processed and split into 4 samples\n",
      "INFO:root:'BarMor.txt' was processed and split into 20 samples\n",
      "INFO:root:'AristMet.txt' was processed and split into 6 samples\n",
      "INFO:root:'BarMirab.txt' was processed and split into 7 samples\n",
      "INFO:root:'WilMet.txt' was processed and split into 30 samples\n",
      "INFO:root:'JamPhys.txt' was processed and split into 53 samples\n",
      "INFO:root:'WilInPar.txt' was processed and split into 161 samples\n",
      "INFO:root:'BarMun.txt' was processed and split into 5 samples\n",
      "INFO:root:'WilTet.txt' was processed and split into 33 samples\n",
      "INFO:root:'BarSig.txt' was processed and split into 3 samples\n",
      "INFO:root:'AristPhaP.txt' was processed and split into 0 samples\n",
      "INFO:root:'BarPri.txt' was processed and split into 2 samples\n",
      "INFO:root:'WilInTim.txt' was processed and split into 4 samples\n",
      "INFO:root:'JamMetaph.txt' was processed and split into 15 samples\n",
      "INFO:root:'BurNemP.txt' was processed and split into 0 samples\n",
      "INFO:root:'WilCael.txt' was processed and split into 26 samples\n",
      "INFO:root:'BurGen.txt' was processed and split into 15 samples\n",
      "INFO:root:'BurP.txt' was processed and split into 3 samples\n",
      "INFO:root:'WilHis.txt' was processed and split into 39 samples\n",
      "INFO:root:'AnonPhys.txt' was processed and split into 5 samples\n",
      "INFO:root:'Myst6.txt' was processed and split into 9 samples\n",
      "INFO:root:'Myst5.txt' was processed and split into 1 samples\n",
      "INFO:root:'WilElem.txt' was processed and split into 25 samples\n",
      "INFO:root:'WilSimp.txt' was processed and split into 120 samples\n",
      "INFO:root:'Myst4.txt' was processed and split into 2 samples\n",
      "INFO:root:'JamAnim.txt' was processed and split into 19 samples\n",
      "INFO:root:'Myst1.txt' was processed and split into 5 samples\n",
      "INFO:root:'Myst3.txt' was processed and split into 10 samples\n",
      "INFO:root:'Myst2.txt' was processed and split into 1 samples\n",
      "INFO:root:'WilGenA.txt' was processed and split into 44 samples\n",
      "INFO:root:'BarHom.txt' was processed and split into 1 samples\n",
      "INFO:root:'BurIon.txt' was processed and split into 133 samples\n",
      "INFO:root:'BarPue.txt' was processed and split into 6 samples\n",
      "INFO:root:'BurMat.txt' was processed and split into 66 samples\n",
      "INFO:root:'AristMen.txt' was processed and split into 9 samples\n",
      "INFO:root:'BurMatP.txt' was processed and split into 0 samples\n",
      "INFO:root:'WilAlex.txt' was processed and split into 72 samples\n",
      "INFO:root:'BurEthV.txt' was processed and split into 9 samples\n",
      "INFO:root:'BurFid.txt' was processed and split into 53 samples\n"
     ]
    }
   ],
   "source": [
    "raw_chunks = preprocess_and_slice_text_files('../data/txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['atqui', 'atqvi'], ['aut', 'avt'], ['autem', 'avtem']]\n"
     ]
    }
   ],
   "source": [
    "# list of lists, so we can keep info about spelling variants in individual arrays\n",
    "\n",
    "stops = []\n",
    "\n",
    "with open('../data/functionwords.txt','r') as file:\n",
    "    for line in file:\n",
    "        words = [x for x in line.lower().split() if x != '/']\n",
    "        stops.append(list(set(words)))\n",
    "            \n",
    "print(stops[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translator</th>\n",
       "      <th>Work</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>quoniam quidem ex calido et frigido et sicco e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>sermo non quod nunquam fit in uno eodemque cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>horis anni invenire quartam coniugationem comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>quod necesse est in ea putrefieri omnia incipi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>de ipsis per capitula quantum ad presentia uti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>ostendat quod secundum veritatem est homo cum ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>causative dicere ut hoc tibi soli peccavi et p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>condemnavit peccatum in carne ut iustitia legi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>uxorem suam et concepit et genuit quare propte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>venit oportet igitur primum praedicatum esse e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Translator Work                                              Chunk\n",
       "0           Bur  Com  quoniam quidem ex calido et frigido et sicco e...\n",
       "1           Bur  Com  sermo non quod nunquam fit in uno eodemque cor...\n",
       "2           Bur  Com  horis anni invenire quartam coniugationem comp...\n",
       "3           Bur  Com  quod necesse est in ea putrefieri omnia incipi...\n",
       "4           Bur  Com  de ipsis per capitula quantum ad presentia uti...\n",
       "...         ...  ...                                                ...\n",
       "1180        Bur  Fid  ostendat quod secundum veritatem est homo cum ...\n",
       "1181        Bur  Fid  causative dicere ut hoc tibi soli peccavi et p...\n",
       "1182        Bur  Fid  condemnavit peccatum in carne ut iustitia legi...\n",
       "1183        Bur  Fid  uxorem suam et concepit et genuit quare propte...\n",
       "1184        Bur  Fid  venit oportet igitur primum praedicatum esse e...\n",
       "\n",
       "[1185 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is tied to our particular filename convention\n",
    "# TranslatorWorkNamePossiblySeveralWords.txt\n",
    "\n",
    "entries = []\n",
    "for k, txt in raw_chunks.items():\n",
    "    # grab the part before the chunk number in the key, split into translator\n",
    "    # and work. `if x` drops empty strings that come from re.split.\n",
    "    ww = [x for x in re.split('([A-Z][a-z]*)', k.split('_')[0]) if x]\n",
    "    transl = ww[0]\n",
    "    work = ''.join(ww[1:])\n",
    "    chunk = ' '.join(txt)\n",
    "    entries.append({\n",
    "        'Translator' : transl,\n",
    "        'Work' : work,\n",
    "        'Chunk' : chunk\n",
    "        })\n",
    "chunk_df = pd.DataFrame(entries)\n",
    "chunk_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Com', 'Pha', 'Int', 'Metaph', 'EthN', 'Mor', 'Met', 'Mirab',\n",
       "       'Phys', 'InPar', 'Mun', 'Tet', 'Sig', 'Pri', 'InTim', 'Cael',\n",
       "       'Gen', 'P', 'His', '6', '5', 'Elem', 'Simp', '4', 'Anim', '1', '3',\n",
       "       '2', 'GenA', 'Hom', 'Ion', 'Pue', 'Mat', 'Men', 'Alex', 'EthV',\n",
       "       'Fid'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_df.Work.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_stops = [item for sublist in stops for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doing this without IDF really just makes it a normalised CountVectorizer. Not\n",
    "# using IDF because the frequency 'boosting' is really a form a fitting, and we\n",
    "# want to save that for the classification algorithms.\n",
    "\n",
    "# L1 vs L2 normalisation is a methodological question. Since we'll be clustering\n",
    "# these as 'points' L2 has slightly more theoretical support, but either would\n",
    "# almost certainly be fine.\n",
    "v = TfidfVectorizer(use_idf=False, analyzer='word', decode_error='replace',norm='l2')\n",
    "# only count our stopwords\n",
    "v.fit(flat_stops)\n",
    "\n",
    "def vectorize(s):\n",
    "    # make a df with all function words\n",
    "    X = v.transform([s])\n",
    "    df = pd.DataFrame(X.toarray())\n",
    "    df.columns = v.get_feature_names_out()\n",
    "\n",
    "    # make a blank df\n",
    "    stops_df_combined = pd.DataFrame()\n",
    "    for ary in stops:\n",
    "        ary = sorted(list(set(ary)))\n",
    "        # each array is a list of spelling variants. sum the counts for all the\n",
    "        # variants of this stopword that appear in the df, using the first array\n",
    "        # entry as the label\n",
    "        stops_df_combined[ary[0]] = df[df.columns.intersection(ary)].sum(axis=1)\n",
    "    return stops_df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atqui</th>\n",
       "      <th>aut</th>\n",
       "      <th>autem</th>\n",
       "      <th>certe</th>\n",
       "      <th>ceu</th>\n",
       "      <th>confestim</th>\n",
       "      <th>cum</th>\n",
       "      <th>dehinc</th>\n",
       "      <th>deinceps</th>\n",
       "      <th>demum</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>sicut</th>\n",
       "      <th>siquidem</th>\n",
       "      <th>tamquam</th>\n",
       "      <th>ut</th>\n",
       "      <th>utique</th>\n",
       "      <th>uelut</th>\n",
       "      <th>ueluti</th>\n",
       "      <th>uero</th>\n",
       "      <th>uidelicet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.534050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145650</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145650</td>\n",
       "      <td>0.218475</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200297</td>\n",
       "      <td>0.578636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222552</td>\n",
       "      <td>0.311573</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230022</td>\n",
       "      <td>0.575055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253024</td>\n",
       "      <td>0.138013</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243044</td>\n",
       "      <td>0.710436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280435</td>\n",
       "      <td>0.168261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.649435</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070591</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014118</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395308</td>\n",
       "      <td>0.211772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587995</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223125</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481621</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156893</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274563</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252099</td>\n",
       "      <td>0.072028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185 rows Ã— 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      atqui       aut     autem  certe  ceu  confestim       cum  dehinc  \\\n",
       "0       0.0  0.097100  0.534050    0.0  0.0        0.0  0.145650     0.0   \n",
       "1       0.0  0.200297  0.578636    0.0  0.0        0.0  0.155787     0.0   \n",
       "2       0.0  0.230022  0.575055    0.0  0.0        0.0  0.000000     0.0   \n",
       "3       0.0  0.243044  0.710436    0.0  0.0        0.0  0.037391     0.0   \n",
       "4       0.0  0.649435  0.409426    0.0  0.0        0.0  0.070591     0.0   \n",
       "...     ...       ...       ...    ...  ...        ...       ...     ...   \n",
       "1180    0.0  0.024500  0.538996    0.0  0.0        0.0  0.171499     0.0   \n",
       "1181    0.0  0.000000  0.421459    0.0  0.0        0.0  0.049583     0.0   \n",
       "1182    0.0  0.000000  0.738485    0.0  0.0        0.0  0.096324     0.0   \n",
       "1183    0.0  0.000000  0.666795    0.0  0.0        0.0  0.156893     0.0   \n",
       "1184    0.0  0.000000  0.432169    0.0  0.0        0.0  0.108042     0.0   \n",
       "\n",
       "      deinceps  demum  ...       sic     sicut  siquidem  tamquam        ut  \\\n",
       "0     0.024275    0.0  ...  0.000000  0.000000  0.000000      0.0  0.145650   \n",
       "1     0.000000    0.0  ...  0.000000  0.000000  0.022255      0.0  0.222552   \n",
       "2     0.023002    0.0  ...  0.046004  0.000000  0.000000      0.0  0.253024   \n",
       "3     0.000000    0.0  ...  0.000000  0.000000  0.000000      0.0  0.280435   \n",
       "4     0.014118    0.0  ...  0.000000  0.000000  0.000000      0.0  0.395308   \n",
       "...        ...    ...  ...       ...       ...       ...      ...       ...   \n",
       "1180  0.000000    0.0  ...  0.000000  0.000000  0.000000      0.0  0.587995   \n",
       "1181  0.000000    0.0  ...  0.000000  0.000000  0.000000      0.0  0.223125   \n",
       "1182  0.000000    0.0  ...  0.000000  0.032108  0.000000      0.0  0.481621   \n",
       "1183  0.000000    0.0  ...  0.000000  0.078446  0.000000      0.0  0.274563   \n",
       "1184  0.000000    0.0  ...  0.000000  0.144056  0.000000      0.0  0.252099   \n",
       "\n",
       "        utique     uelut  ueluti      uero  uidelicet  \n",
       "0     0.218475  0.024275     0.0  0.218475        0.0  \n",
       "1     0.311573  0.022255     0.0  0.066766        0.0  \n",
       "2     0.138013  0.046004     0.0  0.230022        0.0  \n",
       "3     0.168261  0.000000     0.0  0.037391        0.0  \n",
       "4     0.211772  0.000000     0.0  0.070591        0.0  \n",
       "...        ...       ...     ...       ...        ...  \n",
       "1180  0.024500  0.000000     0.0  0.024500        0.0  \n",
       "1181  0.049583  0.024792     0.0  0.074375        0.0  \n",
       "1182  0.064216  0.032108     0.0  0.032108        0.0  \n",
       "1183  0.039223  0.000000     0.0  0.039223        0.0  \n",
       "1184  0.072028  0.000000     0.0  0.036014        0.0  \n",
       "\n",
       "[1185 rows x 54 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = pd.concat([vectorize(x) for x in chunk_df.Chunk],axis=0).reset_index(drop=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Translator</th>\n",
       "      <th>Work</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>atqui</th>\n",
       "      <th>aut</th>\n",
       "      <th>autem</th>\n",
       "      <th>certe</th>\n",
       "      <th>ceu</th>\n",
       "      <th>confestim</th>\n",
       "      <th>cum</th>\n",
       "      <th>...</th>\n",
       "      <th>sic</th>\n",
       "      <th>sicut</th>\n",
       "      <th>siquidem</th>\n",
       "      <th>tamquam</th>\n",
       "      <th>ut</th>\n",
       "      <th>utique</th>\n",
       "      <th>uelut</th>\n",
       "      <th>ueluti</th>\n",
       "      <th>uero</th>\n",
       "      <th>uidelicet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>quoniam quidem ex calido et frigido et sicco e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.097100</td>\n",
       "      <td>0.534050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.145650</td>\n",
       "      <td>0.218475</td>\n",
       "      <td>0.024275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.218475</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>sermo non quod nunquam fit in uno eodemque cor...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200297</td>\n",
       "      <td>0.578636</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.155787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.222552</td>\n",
       "      <td>0.311573</td>\n",
       "      <td>0.022255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066766</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>horis anni invenire quartam coniugationem comp...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230022</td>\n",
       "      <td>0.575055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.253024</td>\n",
       "      <td>0.138013</td>\n",
       "      <td>0.046004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230022</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>quod necesse est in ea putrefieri omnia incipi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.243044</td>\n",
       "      <td>0.710436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.280435</td>\n",
       "      <td>0.168261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037391</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Com</td>\n",
       "      <td>de ipsis per capitula quantum ad presentia uti...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.649435</td>\n",
       "      <td>0.409426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395308</td>\n",
       "      <td>0.211772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.070591</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>ostendat quod secundum veritatem est homo cum ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.538996</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.171499</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587995</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.024500</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>causative dicere ut hoc tibi soli peccavi et p...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.421459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.223125</td>\n",
       "      <td>0.049583</td>\n",
       "      <td>0.024792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>condemnavit peccatum in carne ut iustitia legi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.738485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096324</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481621</td>\n",
       "      <td>0.064216</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.032108</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>uxorem suam et concepit et genuit quare propte...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.156893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078446</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.274563</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.039223</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>Bur</td>\n",
       "      <td>Fid</td>\n",
       "      <td>venit oportet igitur primum praedicatum esse e...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.432169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.108042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.144056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.252099</td>\n",
       "      <td>0.072028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.036014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1185 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Translator Work                                              Chunk  \\\n",
       "0           Bur  Com  quoniam quidem ex calido et frigido et sicco e...   \n",
       "1           Bur  Com  sermo non quod nunquam fit in uno eodemque cor...   \n",
       "2           Bur  Com  horis anni invenire quartam coniugationem comp...   \n",
       "3           Bur  Com  quod necesse est in ea putrefieri omnia incipi...   \n",
       "4           Bur  Com  de ipsis per capitula quantum ad presentia uti...   \n",
       "...         ...  ...                                                ...   \n",
       "1180        Bur  Fid  ostendat quod secundum veritatem est homo cum ...   \n",
       "1181        Bur  Fid  causative dicere ut hoc tibi soli peccavi et p...   \n",
       "1182        Bur  Fid  condemnavit peccatum in carne ut iustitia legi...   \n",
       "1183        Bur  Fid  uxorem suam et concepit et genuit quare propte...   \n",
       "1184        Bur  Fid  venit oportet igitur primum praedicatum esse e...   \n",
       "\n",
       "      atqui       aut     autem  certe  ceu  confestim       cum  ...  \\\n",
       "0       0.0  0.097100  0.534050    0.0  0.0        0.0  0.145650  ...   \n",
       "1       0.0  0.200297  0.578636    0.0  0.0        0.0  0.155787  ...   \n",
       "2       0.0  0.230022  0.575055    0.0  0.0        0.0  0.000000  ...   \n",
       "3       0.0  0.243044  0.710436    0.0  0.0        0.0  0.037391  ...   \n",
       "4       0.0  0.649435  0.409426    0.0  0.0        0.0  0.070591  ...   \n",
       "...     ...       ...       ...    ...  ...        ...       ...  ...   \n",
       "1180    0.0  0.024500  0.538996    0.0  0.0        0.0  0.171499  ...   \n",
       "1181    0.0  0.000000  0.421459    0.0  0.0        0.0  0.049583  ...   \n",
       "1182    0.0  0.000000  0.738485    0.0  0.0        0.0  0.096324  ...   \n",
       "1183    0.0  0.000000  0.666795    0.0  0.0        0.0  0.156893  ...   \n",
       "1184    0.0  0.000000  0.432169    0.0  0.0        0.0  0.108042  ...   \n",
       "\n",
       "           sic     sicut  siquidem  tamquam        ut    utique     uelut  \\\n",
       "0     0.000000  0.000000  0.000000      0.0  0.145650  0.218475  0.024275   \n",
       "1     0.000000  0.000000  0.022255      0.0  0.222552  0.311573  0.022255   \n",
       "2     0.046004  0.000000  0.000000      0.0  0.253024  0.138013  0.046004   \n",
       "3     0.000000  0.000000  0.000000      0.0  0.280435  0.168261  0.000000   \n",
       "4     0.000000  0.000000  0.000000      0.0  0.395308  0.211772  0.000000   \n",
       "...        ...       ...       ...      ...       ...       ...       ...   \n",
       "1180  0.000000  0.000000  0.000000      0.0  0.587995  0.024500  0.000000   \n",
       "1181  0.000000  0.000000  0.000000      0.0  0.223125  0.049583  0.024792   \n",
       "1182  0.000000  0.032108  0.000000      0.0  0.481621  0.064216  0.032108   \n",
       "1183  0.000000  0.078446  0.000000      0.0  0.274563  0.039223  0.000000   \n",
       "1184  0.000000  0.144056  0.000000      0.0  0.252099  0.072028  0.000000   \n",
       "\n",
       "      ueluti      uero  uidelicet  \n",
       "0        0.0  0.218475        0.0  \n",
       "1        0.0  0.066766        0.0  \n",
       "2        0.0  0.230022        0.0  \n",
       "3        0.0  0.037391        0.0  \n",
       "4        0.0  0.070591        0.0  \n",
       "...      ...       ...        ...  \n",
       "1180     0.0  0.024500        0.0  \n",
       "1181     0.0  0.074375        0.0  \n",
       "1182     0.0  0.032108        0.0  \n",
       "1183     0.0  0.039223        0.0  \n",
       "1184     0.0  0.036014        0.0  \n",
       "\n",
       "[1185 rows x 57 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops_tidy = pd.concat([chunk_df,X],axis=1)\n",
    "stops_tidy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_tidy.to_csv('../data/corpus.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
